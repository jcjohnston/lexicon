{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import OrderedDict\n",
    "from collections import namedtuple\n",
    "from textwrap import wrap\n",
    "WordNetInfo = namedtuple('WordNetInfo', 'base, pos, number, info')\n",
    "wnl = WordNetLemmatizer()\n",
    "CATS = OrderedDict((['n', 'N'], ['v', 'V'], ['a', 'Adj'], ['s', 'Sat'], ['r', 'Adv']))\n",
    "MAIN = ('definition', 'examples')\n",
    "NYMS = ('synonyms', 'antonyms', 'hypernyms', 'hyponyms',\n",
    "        'part_meronyms', 'part_holonyms', 'substance_meronyms', 'substance_holonyms',\n",
    "        'entailments')\n",
    "TAB = ' ' * 4   # avoid a literal four-space string in case a tabifier alters it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WNLemmatized(word, language='eng'):\n",
    "    '''Use a WordNet lemmatizer to get all stems (lemmas) for word, based on POS.\n",
    "    Return word unchanged for non-existent form-POS combinations.'''\n",
    "    if language != 'eng':\n",
    "        return [word]\n",
    "    lexemes = []\n",
    "    for pos in CATS.keys():\n",
    "        lemma = wnl.lemmatize(word, pos)\n",
    "        if pos == 's' and (word, 'a') in lexemes:\n",
    "            continue\n",
    "        lexemes.append((lemma, pos))\n",
    "    return lexemes\n",
    "\n",
    "def WNNormalized(word):\n",
    "    '''Return a WordNet-normalized version of word: all lower-case and no apostrophes'''\n",
    "    return word.lower().replace(\"'\", '')\n",
    "\n",
    "def appendOnce(lst, elt):\n",
    "    '''Append lst to lst only if elt not already in lst'''\n",
    "    if elt not in lst:\n",
    "        lst.append(elt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WNInfo(word, kinds, language='eng'):\n",
    "    '''Return a list of WordNetInfo tuples of kinds of information for word'''\n",
    "    results = []\n",
    "    for synset in wn.synsets(WNNormalized(word), lang=language):\n",
    "        #base = lemma.name()\n",
    "        #synset = lemma.synset()\n",
    "        synset_base, synset_pos, synset_number = synset.name().split('.')\n",
    "        info = OrderedDict()\n",
    "        # Definition + examples -- from synset only\n",
    "        if 'definition' in kinds:\n",
    "            for kind in kinds:\n",
    "                info[kind] = getattr(synset, kind)()\n",
    "        # Related words\n",
    "        else:\n",
    "            # Synonyms and antonyms need special-casing\n",
    "            synonyms = []\n",
    "            antonyms = []\n",
    "            for lemma in synset.lemmas(lang=language):\n",
    "                # Synonyms\n",
    "                name = lemma.name()\n",
    "                appendOnce(synonyms, name)\n",
    "                # Antonyms\n",
    "                for antonym in lemma.antonyms():\n",
    "                    name = antonym.name()\n",
    "                    appendOnce(antonyms, name)\n",
    "            info['synonyms'] = synonyms\n",
    "            info['antonyms'] = antonyms\n",
    "            # All the others\n",
    "            for kind in kinds[2:]:\n",
    "                nyms = []\n",
    "                for item in getattr(synset, kind)():\n",
    "                    for lemma in item.lemmas(lang=language):\n",
    "                        name = lemma.name()\n",
    "                        appendOnce(nyms, name)\n",
    "                info[kind] = nyms\n",
    "        results.append(WordNetInfo(synset_base, CATS[synset_pos], synset_number, info))\n",
    "    return results\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WNDisplay(wnis, indent=0, maxWidth=70):\n",
    "    '''Return a list of lines containing nicely wrapped and formatted info in wni'''\n",
    "    def wrapped(ind, s, hanging=False):\n",
    "        '''Deal with the indentation and wrapping'''\n",
    "        initialIndent = TAB * ind\n",
    "        subsequentIndent = initialIndent + '  ' if hanging else initialIndent\n",
    "        return wrap(s,\n",
    "                    initial_indent=initialIndent,\n",
    "                    subsequent_indent=subsequentIndent,\n",
    "                    width=maxWidth)\n",
    "    lines = []\n",
    "    if not isinstance(wnis, list):\n",
    "        wnis = [wnis]\n",
    "    for wni in wnis:\n",
    "        lines.extend(wrapped(indent, f'|{wni.base}, {wni.pos}, {wni.number}|'))\n",
    "        for kind in wni.info.keys():\n",
    "            info = wni.info[kind]\n",
    "            if info:   # skip over empty ones\n",
    "                lines.extend(wrapped(indent + 1, f'{kind.title().replace(\"_\", \" \")}:'))\n",
    "                if kind == 'definition':\n",
    "                    lines.extend(wrapped(indent + 2, info, hanging=True))\n",
    "                elif kind == 'examples':\n",
    "                    for example in info:\n",
    "                        lines.extend(wrapped(indent + 2, example, hanging=True))\n",
    "                else:\n",
    "                    lines.extend(wrapped(indent + 2, ' '.join(info), hanging=False))\n",
    "    return lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isPrefix(abb):\n",
    "    '''Return a list of forms of which abb is a prefix'''\n",
    "    full = ('Albania', 'Algeria', 'Azerbaijan', 'France', 'Frisia', 'Friuli', 'Germany', 'Ghana', 'Ghent')\n",
    "    results = []\n",
    "    for name in full:\n",
    "            if name.startswith(abb):\n",
    "                results.append(name)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Frisia']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isPrefix('Fris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('house.n.01.house'),\n",
       " Lemma('firm.n.01.house'),\n",
       " Lemma('house.n.03.house'),\n",
       " Lemma('house.n.04.house'),\n",
       " Lemma('house.n.05.house'),\n",
       " Lemma('house.n.06.house'),\n",
       " Lemma('house.n.07.house'),\n",
       " Lemma('sign_of_the_zodiac.n.01.house'),\n",
       " Lemma('house.n.09.house'),\n",
       " Lemma('family.n.01.house'),\n",
       " Lemma('theater.n.01.house'),\n",
       " Lemma('house.n.12.house'),\n",
       " Lemma('house.v.01.house'),\n",
       " Lemma('house.v.02.house')]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemmas('house')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('house.n.01'),\n",
       " Synset('firm.n.01'),\n",
       " Synset('house.n.03'),\n",
       " Synset('house.n.04'),\n",
       " Synset('house.n.05'),\n",
       " Synset('house.n.06'),\n",
       " Synset('house.n.07'),\n",
       " Synset('sign_of_the_zodiac.n.01'),\n",
       " Synset('house.n.09'),\n",
       " Synset('family.n.01'),\n",
       " Synset('theater.n.01'),\n",
       " Synset('house.n.12'),\n",
       " Synset('house.v.01'),\n",
       " Synset('house.v.02')]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('house')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemmas('houses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('house.n.01'),\n",
       " Synset('firm.n.01'),\n",
       " Synset('house.n.03'),\n",
       " Synset('house.n.04'),\n",
       " Synset('house.n.05'),\n",
       " Synset('house.n.06'),\n",
       " Synset('house.n.07'),\n",
       " Synset('sign_of_the_zodiac.n.01'),\n",
       " Synset('house.n.09'),\n",
       " Synset('family.n.01'),\n",
       " Synset('theater.n.01'),\n",
       " Synset('house.n.12'),\n",
       " Synset('house.v.01'),\n",
       " Synset('house.v.02')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('houses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('good.n.01.good'),\n",
       " Lemma('good.n.02.good'),\n",
       " Lemma('good.n.03.good'),\n",
       " Lemma('commodity.n.01.good'),\n",
       " Lemma('good.a.01.good'),\n",
       " Lemma('full.s.06.good'),\n",
       " Lemma('good.a.03.good'),\n",
       " Lemma('estimable.s.02.good'),\n",
       " Lemma('beneficial.s.01.good'),\n",
       " Lemma('good.s.06.good'),\n",
       " Lemma('good.s.07.good'),\n",
       " Lemma('adept.s.01.good'),\n",
       " Lemma('good.s.09.good'),\n",
       " Lemma('dear.s.02.good'),\n",
       " Lemma('dependable.s.04.good'),\n",
       " Lemma('good.s.12.good'),\n",
       " Lemma('good.s.13.good'),\n",
       " Lemma('effective.s.04.good'),\n",
       " Lemma('good.s.15.good'),\n",
       " Lemma('good.s.16.good'),\n",
       " Lemma('good.s.17.good'),\n",
       " Lemma('good.s.18.good'),\n",
       " Lemma('good.s.19.good'),\n",
       " Lemma('good.s.20.good'),\n",
       " Lemma('good.s.21.good'),\n",
       " Lemma('well.r.01.good'),\n",
       " Lemma('thoroughly.r.02.good')]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemmas('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('good.n.01'),\n",
       " Synset('good.n.02'),\n",
       " Synset('good.n.03'),\n",
       " Synset('commodity.n.01'),\n",
       " Synset('good.a.01'),\n",
       " Synset('full.s.06'),\n",
       " Synset('good.a.03'),\n",
       " Synset('estimable.s.02'),\n",
       " Synset('beneficial.s.01'),\n",
       " Synset('good.s.06'),\n",
       " Synset('good.s.07'),\n",
       " Synset('adept.s.01'),\n",
       " Synset('good.s.09'),\n",
       " Synset('dear.s.02'),\n",
       " Synset('dependable.s.04'),\n",
       " Synset('good.s.12'),\n",
       " Synset('good.s.13'),\n",
       " Synset('effective.s.04'),\n",
       " Synset('good.s.15'),\n",
       " Synset('good.s.16'),\n",
       " Synset('good.s.17'),\n",
       " Synset('good.s.18'),\n",
       " Synset('good.s.19'),\n",
       " Synset('good.s.20'),\n",
       " Synset('good.s.21'),\n",
       " Synset('well.r.01'),\n",
       " Synset('thoroughly.r.02')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#from nltk.corpus import framenet as fn\n",
    "synset = wn.synsets('vocal')[5]\n",
    "lemma = synset.lemmas()[0]\n",
    "#lemma = wn.lemma('vocal.a.01.vocal')\n",
    "print(lemma.frame_strings())\n",
    "print(lemma.pertainyms())\n",
    "print(lemma.derivationally_related_forms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('vocal_music.n.01'),\n",
       " Synset('song.n.01'),\n",
       " Synset('vocal.a.01'),\n",
       " Synset('vocal.a.02'),\n",
       " Synset('outspoken.s.01'),\n",
       " Synset('vocal.s.04')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('vocal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_synset = wn.synsets('good')[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('commodity.n.01')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('commodity.n.01.commodity'),\n",
       " Lemma('commodity.n.01.trade_good'),\n",
       " Lemma('commodity.n.01.good')]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_synset.lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_lemmas = wn.lemmas('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('good.n.01.good'),\n",
       " Lemma('good.n.02.good'),\n",
       " Lemma('good.n.03.good'),\n",
       " Lemma('commodity.n.01.good'),\n",
       " Lemma('good.a.01.good'),\n",
       " Lemma('full.s.06.good'),\n",
       " Lemma('good.a.03.good'),\n",
       " Lemma('estimable.s.02.good'),\n",
       " Lemma('beneficial.s.01.good'),\n",
       " Lemma('good.s.06.good'),\n",
       " Lemma('good.s.07.good'),\n",
       " Lemma('adept.s.01.good'),\n",
       " Lemma('good.s.09.good'),\n",
       " Lemma('dear.s.02.good'),\n",
       " Lemma('dependable.s.04.good'),\n",
       " Lemma('good.s.12.good'),\n",
       " Lemma('good.s.13.good'),\n",
       " Lemma('effective.s.04.good'),\n",
       " Lemma('good.s.15.good'),\n",
       " Lemma('good.s.16.good'),\n",
       " Lemma('good.s.17.good'),\n",
       " Lemma('good.s.18.good'),\n",
       " Lemma('good.s.19.good'),\n",
       " Lemma('good.s.20.good'),\n",
       " Lemma('good.s.21.good'),\n",
       " Lemma('well.r.01.good'),\n",
       " Lemma('thoroughly.r.02.good')]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma('good.n.01.good') --> Synset('good.n.01')\n",
      "Lemma('good.n.02.good') --> Synset('good.n.02')\n",
      "Lemma('good.n.03.good') --> Synset('good.n.03')\n",
      "Lemma('commodity.n.01.good') --> Synset('commodity.n.01')\n",
      "Lemma('good.a.01.good') --> Synset('good.a.01')\n",
      "Lemma('full.s.06.good') --> Synset('full.s.06')\n",
      "Lemma('good.a.03.good') --> Synset('good.a.03')\n",
      "Lemma('estimable.s.02.good') --> Synset('estimable.s.02')\n",
      "Lemma('beneficial.s.01.good') --> Synset('beneficial.s.01')\n",
      "Lemma('good.s.06.good') --> Synset('good.s.06')\n",
      "Lemma('good.s.07.good') --> Synset('good.s.07')\n",
      "Lemma('adept.s.01.good') --> Synset('adept.s.01')\n",
      "Lemma('good.s.09.good') --> Synset('good.s.09')\n",
      "Lemma('dear.s.02.good') --> Synset('dear.s.02')\n",
      "Lemma('dependable.s.04.good') --> Synset('dependable.s.04')\n",
      "Lemma('good.s.12.good') --> Synset('good.s.12')\n",
      "Lemma('good.s.13.good') --> Synset('good.s.13')\n",
      "Lemma('effective.s.04.good') --> Synset('effective.s.04')\n",
      "Lemma('good.s.15.good') --> Synset('good.s.15')\n",
      "Lemma('good.s.16.good') --> Synset('good.s.16')\n",
      "Lemma('good.s.17.good') --> Synset('good.s.17')\n",
      "Lemma('good.s.18.good') --> Synset('good.s.18')\n",
      "Lemma('good.s.19.good') --> Synset('good.s.19')\n",
      "Lemma('good.s.20.good') --> Synset('good.s.20')\n",
      "Lemma('good.s.21.good') --> Synset('good.s.21')\n",
      "Lemma('well.r.01.good') --> Synset('well.r.01')\n",
      "Lemma('thoroughly.r.02.good') --> Synset('thoroughly.r.02')\n"
     ]
    }
   ],
   "source": [
    "for lemma in good_lemmas:\n",
    "    print(lemma, '-->', lemma.synset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "bon_lemmas = wn.lemmas('bon', lang='fra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('well.r.01.bon'),\n",
       " Lemma('okay.r.01.bon'),\n",
       " Lemma('very_well.r.02.bon'),\n",
       " Lemma('thoroughly.r.02.bon'),\n",
       " Lemma('beneficial.s.01.bon'),\n",
       " Lemma('full.s.06.bon'),\n",
       " Lemma('proper.s.04.bon'),\n",
       " Lemma('propitious.a.01.bon'),\n",
       " Lemma('right.r.04.bon'),\n",
       " Lemma('dear.s.02.bon'),\n",
       " Lemma('correct.a.01.bon'),\n",
       " Lemma('smooth.s.07.bon'),\n",
       " Lemma('good.s.21.bon'),\n",
       " Lemma('effective.s.04.bon'),\n",
       " Lemma('good.s.13.bon'),\n",
       " Lemma('good.s.20.bon'),\n",
       " Lemma('benevolent.s.03.bon'),\n",
       " Lemma('good.s.19.bon'),\n",
       " Lemma('good.a.01.bon'),\n",
       " Lemma('good.a.03.bon'),\n",
       " Lemma('good.s.18.bon'),\n",
       " Lemma('good.s.17.bon'),\n",
       " Lemma('good.s.16.bon'),\n",
       " Lemma('good.s.06.bon'),\n",
       " Lemma('good.s.12.bon'),\n",
       " Lemma('palatable.a.01.bon'),\n",
       " Lemma('good.s.15.bon'),\n",
       " Lemma('nice.s.03.bon'),\n",
       " Lemma('estimable.s.02.bon'),\n",
       " Lemma('decent.s.01.bon'),\n",
       " Lemma('right.a.01.bon'),\n",
       " Lemma('right.a.04.bon'),\n",
       " Lemma('good.s.07.bon'),\n",
       " Lemma('all_right.s.01.bon'),\n",
       " Lemma('right.s.08.bon'),\n",
       " Lemma('fine.a.05.bon'),\n",
       " Lemma('smooth.a.01.bon'),\n",
       " Lemma('dependable.s.04.bon'),\n",
       " Lemma('sufficient.a.01.bon'),\n",
       " Lemma('well.n.04.bon'),\n",
       " Lemma('good.n.03.bon'),\n",
       " Lemma('good.n.01.bon'),\n",
       " Lemma('coupon.n.02.bon'),\n",
       " Lemma('coupon.n.01.bon'),\n",
       " Lemma('one-liner.n.01.bon'),\n",
       " Lemma('good_guy.n.01.bon'),\n",
       " Lemma('meal_ticket.n.01.bon')]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bon_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "goeds = wn.lemmas('goed', 'n', lang='nld')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('chattel.n.01.goed'),\n",
       " Lemma('property.n.04.goed'),\n",
       " Lemma('estate.n.02.goed'),\n",
       " Lemma('good.n.02.goed'),\n",
       " Lemma('good.n.01.goed'),\n",
       " Lemma('clothing.n.01.goed'),\n",
       " Lemma('possession.n.02.goed'),\n",
       " Lemma('drygoods.n.01.goed')]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "library.n.01\n",
      "loft.n.02\n",
      "porch.n.01\n",
      "study.n.05\n",
      "claque.n.01\n",
      "box_office.n.02\n",
      "circle.n.07\n",
      "dressing_room.n.01\n",
      "greenroom.n.01\n",
      "orchestra.n.02\n",
      "orchestra_pit.n.01\n",
      "parquet.n.02\n",
      "parquet_circle.n.01\n",
      "stage.n.03\n",
      "standing_room.n.01\n",
      "theater_stage.n.01\n",
      "tiered_seat.n.01\n"
     ]
    }
   ],
   "source": [
    "lang = 'eng'\n",
    "house = wn.lemmas('house', lang=lang)\n",
    "for lemma in house:\n",
    "    synset = lemma.synset()\n",
    "    for nym in synset.part_meronyms():\n",
    "        print(nym.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'property.n.04'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goed.synset().name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goed.antonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lemma('property.n.04.goed')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "maison = wn.lemmas('maison', lang='fra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "definition() got an unexpected keyword argument 'lang'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-201-26bbdb045da5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmaison\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefinition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fra'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: definition() got an unexpected keyword argument 'lang'"
     ]
    }
   ],
   "source": [
    "maison[3].synset().definition(lang='fra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wn.synsets('see', lang='eng'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordNetInfo(base='house', pos='V', number='01', info=OrderedDict([('definition', 'contain or cover'), ('examples', ['This box houses the gears'])])),\n",
       " WordNetInfo(base='house', pos='V', number='02', info=OrderedDict([('definition', 'provide housing for'), ('examples', ['The immigrants were housed in a new development outside the town'])]))]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WNInfo('housed', MAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'WordNetCorpusReader' object has no attribute 'all_lemmas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-449d5961dbea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_lemmas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'WordNetCorpusReader' object has no attribute 'all_lemmas'"
     ]
    }
   ],
   "source": [
    "wn.all_lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = wn.all_synsets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117659"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "OPTIONS = namedtuple('OPTIONS', 'ICASE IDIAC LANGUAGE LEXICON EXE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPT = OPTIONS('icase', 'idiac', 'language', 'lexicon', 'exec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'icase'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OPT.ICASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIONS.icase = 'foo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = ('icase', 'idiac', 'language', 'lexicon', 'exec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTIONS(icase='icase', idiac='idiac', language='language', lexicon='lexicon', exec='exec')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'icase'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-12e0a7d0ed45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0micase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'icase'"
     ]
    }
   ],
   "source": [
    "options.icase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class option(Enum):\n",
    "    ICASE = 'icase'\n",
    "    IDIAC = 'idiac'\n",
    "    LANGUAGE = 'language'\n",
    "    LEXICON = 'lexicon'\n",
    "    EXEC = 'exec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<option.IDIAC: 'idiac'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "option.IDIAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'idiac'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(option.IDIAC.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROGID = namedtuple('PROGID', 'NAME VERSION COPYRIGHT '  'THANKS_PLAIN THANKS_RICH')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = PROGID(NAME = 'foo', VERSION=1, COPYRIGHT='free', THANKS_PLAIN='Ta!', THANKS_RICH='Thank you very much')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog = wn.synsets('dog')[0].lemmas()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lemma('dog.n.01.dog')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.derivationally_related_forms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
