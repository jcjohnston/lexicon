{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import OrderedDict\n",
    "from collections import namedtuple\n",
    "from textwrap import wrap\n",
    "WordNetInfo = namedtuple('WordNetInfo', 'base, pos, number, info')\n",
    "wnl = WordNetLemmatizer()\n",
    "CATS = OrderedDict((['n', 'N'], ['v', 'V'], ['a', 'Adj'], ['s', 'Sat'], ['r', 'Adv']))\n",
    "MAIN = ('definition', 'examples')\n",
    "NYMS = ('synonyms', 'antonyms', 'hypernyms', 'hyponyms',\n",
    "        'part_meronyms', 'part_holonyms', 'substance_meronyms', 'substance_holonyms',\n",
    "        'entailments')\n",
    "TAB = ' ' * 4   # avoid a literal four-space string in case a tabifier alters it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WNLemmatized(word):\n",
    "    '''Use a WordNet lemmatizer to get all stems (lemmas) for word, based on POS.\n",
    "    Return word unchanged for non-existent form-POS combinations.'''\n",
    "    lexemes = []\n",
    "    for pos in CATS.keys():\n",
    "        lemma = wnl.lemmatize(word, pos)\n",
    "        if pos == 's' and (word, 'a') in lexemes:\n",
    "            continue\n",
    "        lexemes.append((lemma, pos))\n",
    "    return lexemes\n",
    "\n",
    "def WNNormalized(word):\n",
    "    '''Return a WordNet-normalized version of word: all lower-case and no apostrophes'''\n",
    "    return word.lower().replace(\"'\", '')\n",
    "\n",
    "def appendOnce(lst, elt):\n",
    "    '''Append lst to lst only if elt not already in lst'''\n",
    "    if elt not in lst:\n",
    "        lst.append(elt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WNInfo(word, kinds, language):\n",
    "    '''Return a list of WordNetInfo tuples of kinds of information for word'''\n",
    "    if language == 'eng':\n",
    "        lexemes = WNLemmatized(WNNormalized(word))\n",
    "    else:\n",
    "        lexemes = [word]\n",
    "    results = []\n",
    "    for lexeme in lexemes:\n",
    "        if language == 'eng':\n",
    "            base, pos = lexeme\n",
    "            senses = wn.synsets(base, pos, lang=language)\n",
    "        else:\n",
    "            base = lexeme\n",
    "            senses = wn.synsets(base, lang=language)\n",
    "        for sense in senses:\n",
    "            sense_base, sense_pos, sense_number = sense.name().split('.')\n",
    "            info = OrderedDict()\n",
    "            # Definition + examples\n",
    "            if 'definition' in kinds:\n",
    "                if sense_base != base:   # only true lemmas, not synonyms\n",
    "                    continue\n",
    "                for kind in kinds:\n",
    "                    info[kind] = getattr(sense, kind)()\n",
    "            # Related words\n",
    "            else:\n",
    "                # Synonyms and antonyms need special-casing\n",
    "                synonyms = []\n",
    "                antonyms = []\n",
    "                # Synonyms\n",
    "                if sense_base != base:\n",
    "                    synonyms.append(sense_base)\n",
    "                for lemma in sense.lemmas(lang=language):\n",
    "                    name = lemma.name()\n",
    "                    if name != base and name != sense_base:\n",
    "                        appendOnce(synonyms, name)\n",
    "                    # Antonyms\n",
    "                    for antonym in lemma.antonyms():\n",
    "                        name = antonym.name()\n",
    "                        appendOnce(antonyms, name)\n",
    "                info['synonyms'] = synonyms\n",
    "                info['antonyms'] = antonyms\n",
    "                # All the others\n",
    "                for kind in kinds[2:]:\n",
    "                    thing = []\n",
    "                    #for item in getattr(sense, kind)():\n",
    "                    for item in getattr(sense, kind)():\n",
    "                        for lemma in item.lemmas(lang=language):\n",
    "                            name, *_ = lemma.name().split('.')\n",
    "                            appendOnce(thing, name)\n",
    "                    info[kind] = thing\n",
    "            results.append(WordNetInfo(sense_base, CATS[sense_pos], sense_number, info))\n",
    "    return results\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "well (Adv, 01)\n",
      "    Synonyms:\n",
      "        well alors bien puits\n",
      "okay (Adv, 01)\n",
      "    Synonyms:\n",
      "        okay alors bien comme_ça est_bon proprement\n",
      "very_well (Adv, 02)\n",
      "    Synonyms:\n",
      "        very_well bien OK\n",
      "thoroughly (Adv, 02)\n",
      "    Synonyms:\n",
      "        thoroughly absolument complètement entièrement exhaustivement\n",
      "beneficial (Sat, 01)\n",
      "    Synonyms:\n",
      "        beneficial\n",
      "full (Sat, 06)\n",
      "    Synonyms:\n",
      "        full entier meilleur plein\n",
      "proper (Sat, 04)\n",
      "    Synonyms:\n",
      "        proper adéquat approprié apte convenable correct exact juste\n",
      "        propre\n",
      "propitious (Adj, 01)\n",
      "    Synonyms:\n",
      "        propitious propice\n",
      "right (Adv, 04)\n",
      "    Synonyms:\n",
      "        right droit\n",
      "dear (Sat, 02)\n",
      "    Synonyms:\n",
      "        dear cher coûteux\n",
      "correct (Adj, 01)\n",
      "    Synonyms:\n",
      "        correct corriger\n",
      "    Antonyms:\n",
      "        incorrect\n",
      "smooth (Sat, 07)\n",
      "    Synonyms:\n",
      "        smooth lisse\n",
      "good (Sat, 21)\n",
      "    Synonyms:\n",
      "        good meilleur\n",
      "effective (Sat, 04)\n",
      "    Synonyms:\n",
      "        effective efficace\n",
      "good (Sat, 13)\n",
      "    Synonyms:\n",
      "        good bien meilleur puits\n",
      "good (Sat, 20)\n",
      "    Synonyms:\n",
      "        good meilleur\n",
      "benevolent (Sat, 03)\n",
      "    Synonyms:\n",
      "        benevolent\n",
      "good (Sat, 19)\n",
      "    Synonyms:\n",
      "        good meilleur\n",
      "good (Adj, 01)\n",
      "    Synonyms:\n",
      "        good\n",
      "good (Adj, 03)\n",
      "    Synonyms:\n",
      "        good meilleur\n",
      "good (Sat, 18)\n",
      "    Synonyms:\n",
      "        good bienfaisant bienfaisante salutaire\n",
      "good (Sat, 17)\n",
      "    Synonyms:\n",
      "        good sage sain son\n",
      "good (Sat, 16)\n",
      "    Synonyms:\n",
      "        good sérieux\n",
      "good (Sat, 06)\n",
      "    Synonyms:\n",
      "        good\n",
      "good (Sat, 12)\n",
      "    Synonyms:\n",
      "        good droit\n",
      "palatable (Adj, 01)\n",
      "    Synonyms:\n",
      "        palatable acceptable appétant gout passable savoureux\n",
      "        succulent tolérable\n",
      "good (Sat, 15)\n",
      "    Synonyms:\n",
      "        good\n",
      "nice (Sat, 03)\n",
      "    Synonyms:\n",
      "        nice\n",
      "estimable (Sat, 02)\n",
      "    Synonyms:\n",
      "        estimable\n",
      "decent (Sat, 01)\n",
      "    Synonyms:\n",
      "        decent décent\n",
      "right (Adj, 01)\n",
      "    Synonyms:\n",
      "        right droit juste\n",
      "right (Adj, 04)\n",
      "    Synonyms:\n",
      "        right convenable droit\n",
      "good (Sat, 07)\n",
      "    Synonyms:\n",
      "        good juste vertueux\n",
      "all_right (Sat, 01)\n",
      "    Synonyms:\n",
      "        all_right aller bien bien_aller en_forme fin satisfaisant\n",
      "right (Sat, 08)\n",
      "    Synonyms:\n",
      "        right droit juste\n",
      "fine (Adj, 05)\n",
      "    Synonyms:\n",
      "        fine\n",
      "smooth (Adj, 01)\n",
      "    Synonyms:\n",
      "        smooth lisse\n",
      "dependable (Sat, 04)\n",
      "    Synonyms:\n",
      "        dependable coffre-fort sûr\n",
      "sufficient (Adj, 01)\n",
      "    Synonyms:\n",
      "        sufficient suffisant\n",
      "well (N, 04)\n",
      "    Synonyms:\n",
      "        well bien puits\n",
      "good (N, 03)\n",
      "    Synonyms:\n",
      "        good bien\n",
      "    Hypernyms:\n",
      "        propriété qualité\n",
      "    Hyponyms:\n",
      "        aide avantage bénéfice intérêt profit salut utilité meilleur\n",
      "        optimum sagesse\n",
      "good (N, 01)\n",
      "    Synonyms:\n",
      "        good humour intérêt\n",
      "    Hypernyms:\n",
      "        avantage\n",
      "    Hyponyms:\n",
      "        intérêt_général\n",
      "coupon (N, 02)\n",
      "    Synonyms:\n",
      "        coupon\n",
      "    Hypernyms:\n",
      "        échantillon exemple prise\n",
      "coupon (N, 01)\n",
      "    Synonyms:\n",
      "        coupon ticket\n",
      "    Hyponyms:\n",
      "        ticket-restaurant\n",
      "one-liner (N, 01)\n",
      "    Synonyms:\n",
      "        one-liner bon_mot mot mot_d'esprit\n",
      "    Hypernyms:\n",
      "        badinage badiner plaisanter rire\n",
      "good_guy (N, 01)\n",
      "    Synonyms:\n",
      "        good_guy\n",
      "    Hypernyms:\n",
      "        être_humain homme humain individu personne quelqu'un quelqu’un\n",
      "meal_ticket (N, 01)\n",
      "    Synonyms:\n",
      "        meal_ticket ticket-restaurant\n",
      "    Hypernyms:\n",
      "        gagne-pain maintenir ressource subsistance\n"
     ]
    }
   ],
   "source": [
    "for line in WNDisplay(WNInfo('bon', NYMS, language='fra')): print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a dwelling that serves as living quarters for one or more families\n",
      "aristocratic family line\n",
      "where you live at a particular time\n"
     ]
    }
   ],
   "source": [
    "for synset in wn.synsets('dom', lang='pol'): print(synset.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('good.n.01'), Synset('good.n.02'), Synset('good.n.03'), Synset('commodity.n.01'), Synset('good.a.01'), Synset('full.s.06'), Synset('good.a.03'), Synset('estimable.s.02'), Synset('beneficial.s.01'), Synset('good.s.06'), Synset('good.s.07'), Synset('adept.s.01'), Synset('good.s.09'), Synset('dear.s.02'), Synset('dependable.s.04'), Synset('good.s.12'), Synset('good.s.13'), Synset('effective.s.04'), Synset('good.s.15'), Synset('good.s.16'), Synset('good.s.17'), Synset('good.s.18'), Synset('good.s.19'), Synset('good.s.20'), Synset('good.s.21'), Synset('well.r.01'), Synset('thoroughly.r.02')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_frame_ids',\n",
       " '_frame_strings',\n",
       " '_hypernyms',\n",
       " '_instance_hypernyms',\n",
       " '_key',\n",
       " '_lang',\n",
       " '_lex_id',\n",
       " '_lexname_index',\n",
       " '_name',\n",
       " '_related',\n",
       " '_synset',\n",
       " '_syntactic_marker',\n",
       " '_wordnet_corpus_reader',\n",
       " 'also_sees',\n",
       " 'antonyms',\n",
       " 'attributes',\n",
       " 'causes',\n",
       " 'count',\n",
       " 'derivationally_related_forms',\n",
       " 'entailments',\n",
       " 'frame_ids',\n",
       " 'frame_strings',\n",
       " 'hypernyms',\n",
       " 'hyponyms',\n",
       " 'in_region_domains',\n",
       " 'in_topic_domains',\n",
       " 'in_usage_domains',\n",
       " 'instance_hypernyms',\n",
       " 'instance_hyponyms',\n",
       " 'key',\n",
       " 'lang',\n",
       " 'member_holonyms',\n",
       " 'member_meronyms',\n",
       " 'name',\n",
       " 'part_holonyms',\n",
       " 'part_meronyms',\n",
       " 'pertainyms',\n",
       " 'region_domains',\n",
       " 'similar_tos',\n",
       " 'substance_holonyms',\n",
       " 'substance_meronyms',\n",
       " 'synset',\n",
       " 'syntactic_marker',\n",
       " 'topic_domains',\n",
       " 'usage_domains',\n",
       " 'verb_groups']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synsets = wn.synsets('good')\n",
    "print(synsets)\n",
    "synset = synsets[3]\n",
    "dir(synset.lemmas()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WNDisplay(wnis, indent=0, maxWidth=70):\n",
    "    '''Return a list of lines containing nicely wrapped and formatted info in wni'''\n",
    "    def wrapped(ind, s, hanging=False):\n",
    "        '''Deal with the indentation and wrapping'''\n",
    "        initialIndent = TAB * ind\n",
    "        subsequentIndent = initialIndent + '  ' if hanging else initialIndent\n",
    "        return wrap(s,\n",
    "                    initial_indent=initialIndent,\n",
    "                    subsequent_indent=subsequentIndent,\n",
    "                    width=maxWidth)\n",
    "    lines = []\n",
    "    if not isinstance(wnis, list):\n",
    "        wnis = [wnis]\n",
    "    for wni in wnis:\n",
    "        lines.extend(wrapped(indent, f'{wni.base} ({wni.pos}, {wni.number})'))\n",
    "        for kind in wni.info.keys():\n",
    "            info = wni.info[kind]\n",
    "            if info:   # skip over empty ones\n",
    "                lines.extend(wrapped(indent + 1, f'{kind.title().replace(\"_\", \" \")}:'))\n",
    "                if kind == 'definition':\n",
    "                    lines.extend(wrapped(indent + 2, info, hanging=True))\n",
    "                elif kind == 'examples':\n",
    "                    for example in info:\n",
    "                        lines.extend(wrapped(indent + 2, example, hanging=True))\n",
    "                else:\n",
    "                    lines.extend(wrapped(indent + 2, ' '.join(info), hanging=False))\n",
    "    return lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good (N, 01)\n",
      "    Hypernyms:\n",
      "        advantage\n",
      "    Hyponyms:\n",
      "        common_good\n",
      "good (N, 02)\n",
      "    Synonyms:\n",
      "        goodness\n",
      "    Antonyms:\n",
      "        evil evilness\n",
      "    Hypernyms:\n",
      "        morality\n",
      "    Hyponyms:\n",
      "        beneficence benignity kindness saintliness summum_bonum virtue\n",
      "good (N, 03)\n",
      "    Synonyms:\n",
      "        goodness\n",
      "    Antonyms:\n",
      "        bad badness\n",
      "    Hypernyms:\n",
      "        quality\n",
      "    Hyponyms:\n",
      "        benefit better desirability optimum wisdom worthiness\n",
      "commodity (N, 01)\n",
      "    Synonyms:\n",
      "        commodity trade_good\n",
      "    Hypernyms:\n",
      "        artifact\n",
      "    Hyponyms:\n",
      "        basic consumer_goods drygoods entrant export fancy_goods\n",
      "        fungible future import merchandise middling salvage shopping\n",
      "        sporting_goods worldly_possession\n",
      "good (Adj, 01)\n",
      "    Antonyms:\n",
      "        bad\n",
      "full (Sat, 06)\n",
      "    Synonyms:\n",
      "        full\n",
      "good (Adj, 03)\n",
      "    Antonyms:\n",
      "        evil\n",
      "estimable (Sat, 02)\n",
      "    Synonyms:\n",
      "        estimable honorable respectable\n",
      "beneficial (Sat, 01)\n",
      "    Synonyms:\n",
      "        beneficial\n",
      "good (Sat, 06)\n",
      "good (Sat, 07)\n",
      "    Synonyms:\n",
      "        just upright\n",
      "adept (Sat, 01)\n",
      "    Synonyms:\n",
      "        adept expert practiced proficient skillful skilful\n",
      "good (Sat, 09)\n",
      "dear (Sat, 02)\n",
      "    Synonyms:\n",
      "        dear near\n",
      "dependable (Sat, 04)\n",
      "    Synonyms:\n",
      "        dependable safe secure\n",
      "good (Sat, 12)\n",
      "    Synonyms:\n",
      "        right ripe\n",
      "good (Sat, 13)\n",
      "    Synonyms:\n",
      "        well\n",
      "effective (Sat, 04)\n",
      "    Synonyms:\n",
      "        effective in_effect in_force\n",
      "good (Sat, 15)\n",
      "good (Sat, 16)\n",
      "    Synonyms:\n",
      "        serious\n",
      "good (Sat, 17)\n",
      "    Synonyms:\n",
      "        sound\n",
      "good (Sat, 18)\n",
      "    Synonyms:\n",
      "        salutary\n",
      "good (Sat, 19)\n",
      "    Synonyms:\n",
      "        honest\n",
      "good (Sat, 20)\n",
      "    Synonyms:\n",
      "        undecomposed unspoiled unspoilt\n",
      "good (Sat, 21)\n",
      "well (Adv, 01)\n",
      "    Synonyms:\n",
      "        well\n",
      "    Antonyms:\n",
      "        ill\n",
      "thoroughly (Adv, 02)\n",
      "    Synonyms:\n",
      "        thoroughly soundly\n"
     ]
    }
   ],
   "source": [
    "for line in WNDisplay(WNInfo('good', NYMS)): print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple = 'apple'; pear='pear'; banana='banana'; water='water'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We have apples, pears and bananas but no water'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'We have {apple}s, {pear}s and {banana}s but no {water}'.format(apple=apple, pear=pear, banana=banana, water=water) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "format() takes no keyword arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ab20de19708f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'We have {apple}s, {pear}s and {banana}s but no {water}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbanana\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbanana\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwater\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwater\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: format() takes no keyword arguments"
     ]
    }
   ],
   "source": [
    "format('We have {apple}s, {pear}s and {banana}s but no {water}', apple=apple, pear=pear, banana=banana, water=water) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,986'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format(1986, ',d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jane, Bob'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{}, {}'.format('Jane', 'Bob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd = open('/home/jason/words/words_prons').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102305"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Argo\\tˈɑrɡo\\n',\n",
       " \"Argo's\\tˈɑrɡoz\\n\",\n",
       " 'Argonaut\\tˈɑrɡənˌɔt\\n',\n",
       " \"Argonaut's\\tˈɑrɡənˌɔts\\n\",\n",
       " 'Argonne\\tˈɑrɡˌɑn, ˈɑrɡˌon\\n',\n",
       " \"Argonne's\\n\",\n",
       " 'Argos\\n',\n",
       " \"Argos's\\n\",\n",
       " 'Argus\\tˈɑrɡəs\\n',\n",
       " \"Argus's\\n\",\n",
       " 'Ariadne\\tˌɛriˈædni\\n',\n",
       " \"Ariadne's\\n\",\n",
       " 'Arianism\\tˈæriənˌɪzəm\\n',\n",
       " \"Arianism's\\n\",\n",
       " 'Ariel\\tˈɛriəl\\n',\n",
       " \"Ariel's\\n\",\n",
       " 'Aries\\tˈɛriz\\n',\n",
       " \"Aries's\\n\",\n",
       " 'Arieses\\n',\n",
       " 'Ariosto\\n',\n",
       " \"Ariosto's\\n\",\n",
       " 'Aristarchus\\n',\n",
       " \"Aristarchus's\\n\",\n",
       " 'Aristides\\n',\n",
       " \"Aristides's\\n\",\n",
       " 'Aristophanes\\tˌærəstˈɔfəniz\\n',\n",
       " \"Aristophanes's\\n\",\n",
       " 'Aristotelian\\tɝˌɪstətˈiliən\\n',\n",
       " \"Aristotelian's\\n\",\n",
       " 'Aristotle\\tˈɛrəstˌɑtəl\\n',\n",
       " \"Aristotle's\\tˈɛrəstˌɑtəlz\\n\",\n",
       " 'Arius\\n',\n",
       " \"Arius's\\n\",\n",
       " 'Arizona\\tˌɛrɪzˈonə\\n',\n",
       " \"Arizona's\\tˌɛrɪzˈonəz\\n\",\n",
       " 'Arizonan\\tɝˈɪzonən, ɝɪzˈonən\\n',\n",
       " \"Arizonan's\\n\",\n",
       " 'Arizonans\\tɝˈɪzonənz, ɝɪzˈonənz\\n',\n",
       " 'Arizonian\\n',\n",
       " \"Arizonian's\\n\",\n",
       " 'Arizonians\\n',\n",
       " 'Arjuna\\n',\n",
       " \"Arjuna's\\n\",\n",
       " 'Arkansan\\tˌɑrkˈænzən\\n',\n",
       " \"Arkansan's\\n\",\n",
       " 'Arkansas\\tˈɑrkənsˌɑ\\n',\n",
       " \"Arkansas's\\tˈɑrkənsˌɑz\\n\",\n",
       " 'Arkhangelsk\\n',\n",
       " \"Arkhangelsk's\\n\",\n",
       " 'Arkwright\\tˈɑrkrˌɑɪt\\n',\n",
       " \"Arkwright's\\n\",\n",
       " 'Arlene\\tˈɑrlˌin\\n',\n",
       " \"Arlene's\\tˈɑrlˌinz\\n\",\n",
       " 'Arline\\tˈɑrlˌɑɪn\\n',\n",
       " \"Arline's\\n\",\n",
       " 'Arlington\\tˈɑrlɪŋtən\\n',\n",
       " \"Arlington's\\tˈɑrlɪŋtənz\\n\",\n",
       " 'Armageddon\\tˌɑrməɡˈɛdən\\n',\n",
       " \"Armageddon's\\n\",\n",
       " 'Armageddons\\n',\n",
       " 'Armagnac\\n',\n",
       " \"Armagnac's\\n\",\n",
       " 'Armand\\tˈɑrmɑnd, ˌɑrmˈɑnd\\n',\n",
       " \"Armand's\\n\",\n",
       " 'Armando\\tɑrmˈɑndo\\n',\n",
       " \"Armando's\\n\",\n",
       " 'Armani\\tˌɑrmˈɑni\\n',\n",
       " \"Armani's\\n\",\n",
       " 'Armenia\\tɑrmˈiniə\\n',\n",
       " \"Armenia's\\tɑrmˈiniəz\\n\",\n",
       " 'Armenian\\tɑrmˈiniən\\n',\n",
       " \"Armenian's\\n\",\n",
       " 'Armenians\\tɑrmˈiniənz\\n',\n",
       " 'Arminius\\n',\n",
       " \"Arminius's\\n\",\n",
       " 'Armonk\\tˈɑrməŋk\\n',\n",
       " \"Armonk's\\n\",\n",
       " 'Armour\\tˈɑrmɝ\\n',\n",
       " \"Armour's\\n\",\n",
       " 'Armstrong\\tˈɑrmstrˌɑŋ, ˈɑrmstrˌɔŋ\\n',\n",
       " \"Armstrong's\\tˈɑrmstrˌɔŋz\\n\",\n",
       " 'Arneb\\n',\n",
       " \"Arneb's\\n\",\n",
       " 'Arnhem\\n',\n",
       " \"Arnhem's\\n\",\n",
       " 'Arno\\tˈɑrno\\n',\n",
       " \"Arno's\\n\",\n",
       " 'Arnold\\tˈɑrnəld\\n',\n",
       " \"Arnold's\\tˈɑrnəldz\\n\",\n",
       " 'Arnulfo\\tɑrnˈəlfo\\n',\n",
       " \"Arnulfo's\\n\",\n",
       " 'Aron\\tˈɛrən\\n',\n",
       " \"Aron's\\n\",\n",
       " 'Arrhenius\\n',\n",
       " \"Arrhenius's\\n\",\n",
       " 'Arron\\n',\n",
       " \"Arron's\\n\",\n",
       " 'Art\\tˈɑrt\\n',\n",
       " \"Art's\\tˈɑrts\\n\",\n",
       " 'Artaxerxes\\n',\n",
       " \"Artaxerxes's\\n\",\n",
       " 'Artemis\\n',\n",
       " \"Artemis's\\n\",\n",
       " 'Arthur\\tˈɑrθɝ\\n',\n",
       " \"Arthur's\\tˈɑrθɝz\\n\",\n",
       " 'Arthurian\\tɑrθˈʊriən\\n',\n",
       " \"Arthurian's\\n\",\n",
       " 'Artie\\tˈɑrti\\n',\n",
       " \"Artie's\\n\",\n",
       " 'Arturo\\tɑrtˈʊro\\n',\n",
       " \"Arturo's\\n\",\n",
       " 'Aruba\\tɝˈubə\\n',\n",
       " \"Aruba's\\n\",\n",
       " 'Aryan\\tˈɑriən\\n',\n",
       " \"Aryan's\\n\",\n",
       " 'Aryans\\n',\n",
       " 'As\\tˈæz, ˈɛz\\n',\n",
       " \"As's\\n\",\n",
       " 'Asama\\n',\n",
       " \"Asama's\\n\",\n",
       " 'Ascella\\n',\n",
       " \"Ascella's\\n\",\n",
       " 'Asgard\\tˈɑsɡˌɑrd\\n',\n",
       " \"Asgard's\\n\",\n",
       " 'Ashanti\\n',\n",
       " \"Ashanti's\\n\",\n",
       " 'Ashcroft\\tˈæʃkrˌɔft\\n',\n",
       " \"Ashcroft's\\n\",\n",
       " 'Ashe\\tˈæʃ\\n',\n",
       " \"Ashe's\\tˈæʃɪz\\n\",\n",
       " 'Ashikaga\\n',\n",
       " \"Ashikaga's\\n\",\n",
       " 'Ashkenazim\\n',\n",
       " \"Ashkenazim's\\n\",\n",
       " 'Ashkhabad\\n',\n",
       " \"Ashkhabad's\\n\",\n",
       " 'Ashlee\\n',\n",
       " \"Ashlee's\\n\",\n",
       " 'Ashley\\tˈæʃli\\n',\n",
       " \"Ashley's\\tˈæʃliz\\n\",\n",
       " 'Ashmolean\\n',\n",
       " \"Ashmolean's\\n\",\n",
       " 'Ashurbanipal\\n',\n",
       " \"Ashurbanipal's\\n\",\n",
       " 'Asia\\tˈeʒə\\n',\n",
       " \"Asia's\\tˈeʒəz\\n\",\n",
       " 'Asiago\\n',\n",
       " 'Asian\\tˈeʒən\\n',\n",
       " \"Asian's\\n\",\n",
       " 'Asians\\tˈeʒənz\\n',\n",
       " 'Asiatic\\tˌeʒiˈætɪk\\n',\n",
       " \"Asiatic's\\n\",\n",
       " 'Asiatics\\n',\n",
       " 'Asimov\\tˈæsɪmɑv, ˈæzɪmɑv\\n',\n",
       " \"Asimov's\\tˈæsɪmɑvz, ˈæzɪmɑvz\\n\",\n",
       " 'Asmara\\tˌæzmˈɑrə\\n',\n",
       " \"Asmara's\\n\",\n",
       " 'Asoka\\n',\n",
       " \"Asoka's\\n\",\n",
       " 'Aspell\\n',\n",
       " \"Aspell's\\n\",\n",
       " 'Aspen\\tˈæspən\\n',\n",
       " \"Aspen's\\tˈæspənz\\n\",\n",
       " 'Asperger\\n',\n",
       " \"Asperger's\\n\",\n",
       " 'Aspidiske\\n',\n",
       " \"Aspidiske's\\n\",\n",
       " 'Asquith\\tˈæskwɪθ\\n',\n",
       " \"Asquith's\\n\",\n",
       " 'Assad\\təsˈɑd\\n',\n",
       " \"Assad's\\təsˈɑdz\\n\",\n",
       " 'Assam\\tˌɑsˈɑm\\n',\n",
       " \"Assam's\\n\",\n",
       " 'Assamese\\n',\n",
       " \"Assamese's\\n\",\n",
       " 'Assisi\\təsˈisi\\n',\n",
       " \"Assisi's\\təsˈisiz\\n\",\n",
       " 'Assyria\\təsˈɪriə\\n',\n",
       " \"Assyria's\\n\",\n",
       " 'Assyrian\\təsˈɪriən\\n',\n",
       " \"Assyrian's\\n\",\n",
       " 'Assyrians\\təsˈɪriənz\\n',\n",
       " 'Astaire\\təstˈɛr\\n',\n",
       " \"Astaire's\\n\",\n",
       " 'Astana\\n',\n",
       " \"Astana's\\n\",\n",
       " 'Astarte\\n',\n",
       " \"Astarte's\\n\",\n",
       " 'Aston\\tˈæstən\\n',\n",
       " \"Aston's\\n\",\n",
       " 'Astor\\tˈæstɝ\\n',\n",
       " \"Astor's\\tˈæstɝz\\n\",\n",
       " 'Astoria\\tˌæstˈɔriə\\n',\n",
       " \"Astoria's\\n\",\n",
       " 'Astrakhan\\tˈæstrəkɑn\\n',\n",
       " \"Astrakhan's\\n\",\n",
       " 'AstroTurf\\tˈæstrotˌɝf\\n',\n",
       " \"AstroTurf's\\n\",\n",
       " 'Asturias\\n',\n",
       " \"Asturias's\\n\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd[1000:1200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jason/.lexitronrc']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read('/home/jason/.lexitronrc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ItemsView(<configparser.ConfigParser object at 0x7fe6a853d438>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('lexicon', '/home/jason/words/english-words_prons.txt')\n",
      "('icase', 'False')\n",
      "('idiac', 'True')\n"
     ]
    }
   ],
   "source": [
    "for item in config.items('DEFAULT'):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jason/words/english-words_prons.txt'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.get('DEFAULT', 'lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'True'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7ff68590290d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DEFAULT'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'idiac'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.6/configparser.py\u001b[0m in \u001b[0;36mgetint\u001b[0;34m(self, section, option, raw, vars, fallback, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m                fallback=_UNSET, **kwargs):\n\u001b[1;32m    818\u001b[0m         return self._get_conv(section, option, int, raw=raw, vars=vars,\n\u001b[0;32m--> 819\u001b[0;31m                               fallback=fallback, **kwargs)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     def getfloat(self, section, option, *, raw=False, vars=None,\n",
      "\u001b[0;32m/usr/lib/python3.6/configparser.py\u001b[0m in \u001b[0;36m_get_conv\u001b[0;34m(self, section, option, conv, raw, vars, fallback, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             return self._get(section, conv, option, raw=raw, vars=vars,\n\u001b[0;32m--> 809\u001b[0;31m                              **kwargs)\n\u001b[0m\u001b[1;32m    810\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNoSectionError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoOptionError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfallback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0m_UNSET\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/configparser.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, section, conv, option, **kwargs)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m     def _get_conv(self, section, option, conv, *, raw=False, vars=None,\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'True'"
     ]
    }
   ],
   "source": [
    "config.getint('DEFAULT', 'idiac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    from nltk.corpus import words\n",
    "    wordlist = words.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236736"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['advisably',\n",
       " 'advisal',\n",
       " 'advisatory',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'advisedly',\n",
       " 'advisedness',\n",
       " 'advisee',\n",
       " 'advisement',\n",
       " 'adviser',\n",
       " 'advisership',\n",
       " 'advisive',\n",
       " 'advisiveness',\n",
       " 'advisor',\n",
       " 'advisorily',\n",
       " 'advisory',\n",
       " 'advocacy',\n",
       " 'advocate',\n",
       " 'advocateship',\n",
       " 'advocatess',\n",
       " 'advocation',\n",
       " 'advocator',\n",
       " 'advocatory',\n",
       " 'advocatress',\n",
       " 'advocatrice',\n",
       " 'advocatrix',\n",
       " 'advolution',\n",
       " 'advowee',\n",
       " 'advowson',\n",
       " 'ady',\n",
       " 'adynamia',\n",
       " 'adynamic',\n",
       " 'adynamy',\n",
       " 'adyta',\n",
       " 'adyton',\n",
       " 'adytum',\n",
       " 'adz',\n",
       " 'adze',\n",
       " 'adzer',\n",
       " 'adzooks',\n",
       " 'ae',\n",
       " 'Aeacides',\n",
       " 'Aeacus',\n",
       " 'Aeaean',\n",
       " 'Aechmophorus',\n",
       " 'aecial',\n",
       " 'Aecidiaceae',\n",
       " 'aecidial',\n",
       " 'aecidioform',\n",
       " 'Aecidiomycetes',\n",
       " 'aecidiospore',\n",
       " 'aecidiostage',\n",
       " 'aecidium',\n",
       " 'aeciospore',\n",
       " 'aeciostage',\n",
       " 'aecioteliospore',\n",
       " 'aeciotelium',\n",
       " 'aecium',\n",
       " 'aedeagus',\n",
       " 'Aedes',\n",
       " 'aedicula',\n",
       " 'aedile',\n",
       " 'aedileship',\n",
       " 'aedilian',\n",
       " 'aedilic',\n",
       " 'aedilitian',\n",
       " 'aedility',\n",
       " 'aedoeagus',\n",
       " 'aefald',\n",
       " 'aefaldness',\n",
       " 'aefaldy',\n",
       " 'aefauld',\n",
       " 'aegagropila',\n",
       " 'aegagropile',\n",
       " 'aegagrus',\n",
       " 'Aegean',\n",
       " 'aegerian',\n",
       " 'aegeriid',\n",
       " 'Aegeriidae',\n",
       " 'Aegialitis',\n",
       " 'aegicrania',\n",
       " 'Aegina',\n",
       " 'Aeginetan',\n",
       " 'Aeginetic',\n",
       " 'Aegipan',\n",
       " 'aegirine',\n",
       " 'aegirinolite',\n",
       " 'aegirite',\n",
       " 'aegis',\n",
       " 'Aegisthus',\n",
       " 'Aegithalos',\n",
       " 'Aegithognathae',\n",
       " 'aegithognathism',\n",
       " 'aegithognathous',\n",
       " 'Aegle',\n",
       " 'Aegopodium',\n",
       " 'aegrotant',\n",
       " 'aegyptilla',\n",
       " 'aegyrite',\n",
       " 'aeluroid']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist[3000:3100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/home/jason/dev/src/python3/prondict/wordlists/nltk-corpus-words-words.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in wordlist:\n",
    "    print(word, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lexicon\n",
    "lex = lexicon.Lexicon('/home/jason/words/medium-combined_prons.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299537, 35245, 38567)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex = lexicon.Lexicon('/home/jason/words/medium-combined_prons.txt', diacBlind = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex.contains('houses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299537, 35245, 38567)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['housing']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex.contains('housing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fiance']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex.contains('fiancé')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex.definitions('fiancé')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpora\n"
     ]
    }
   ],
   "source": [
    "print(wn.subdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method langs in module nltk.corpus.reader.wordnet:\n",
      "\n",
      "langs() method of nltk.corpus.reader.wordnet.WordNetCorpusReader instance\n",
      "    return a list of languages supported by Multilingual Wordnet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(wn.langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('house.n.01'), Synset('house.n.06'), Synset('home.n.01')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('dom', lang='pol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language= eng\n",
      "[Synset('house.n.01'), Synset('firm.n.01'), Synset('house.n.03'), Synset('house.n.04'), Synset('house.n.05'), Synset('house.n.06'), Synset('house.n.07'), Synset('sign_of_the_zodiac.n.01'), Synset('house.n.09'), Synset('family.n.01'), Synset('theater.n.01'), Synset('house.n.12'), Synset('house.v.01'), Synset('house.v.02')]\n",
      "Language= als\n",
      "[]\n",
      "Language= arb\n",
      "[]\n",
      "Language= bul\n",
      "[]\n",
      "Language= cat\n",
      "[]\n",
      "Language= cmn\n",
      "[]\n",
      "Language= dan\n",
      "[]\n",
      "Language= ell\n",
      "[]\n",
      "Language= eus\n",
      "[]\n",
      "Language= fas\n",
      "[]\n",
      "Language= fin\n",
      "[]\n",
      "Language= fra\n",
      "[]\n",
      "Language= glg\n",
      "[]\n",
      "Language= heb\n",
      "[]\n",
      "Language= hrv\n",
      "[]\n",
      "Language= ind\n",
      "[]\n",
      "Language= ita\n",
      "[]\n",
      "Language= jpn\n",
      "[]\n",
      "Language= nld\n",
      "[Synset('house.n.07')]\n",
      "Language= nno\n",
      "[]\n",
      "Language= nob\n",
      "[]\n",
      "Language= pol\n",
      "[]\n",
      "Language= por\n",
      "[]\n",
      "Language= qcn\n",
      "[]\n",
      "Language= slv\n",
      "[]\n",
      "Language= spa\n",
      "[]\n",
      "Language= swe\n",
      "[]\n",
      "Language= tha\n",
      "[]\n",
      "Language= zsm\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for lg in wn.langs():\n",
    "    print('Language=', lg)\n",
    "    print(wn.synsets('house', lang=lg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isPrefix(abb):\n",
    "    '''Return a list of forms of which abb is a prefix'''\n",
    "    full = ('Albania', 'Algeria', 'Azerbaijan', 'France', 'Frisia', 'Friuli', 'Germany', 'Ghana', 'Ghent')\n",
    "    results = []\n",
    "    for name in full:\n",
    "            if name.startswith(abb):\n",
    "                results.append(name)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Frisia']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isPrefix('Fris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
